{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014aa028-e81d-4897-bae9-e7a353b18826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch langchain databricks-sdk pdfplumber pymupdf tiktoken pyyaml\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ebd8bd2-afa2-4234-806b-5bb4d8bb41fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from config.loader import init_config, get_config, save_config\n",
    "config_path = '/Workspace/Users/benjamin.wynn@peraton.com/GEMRAG/config/base_config.yaml'\n",
    "init_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c31ff29-da63-41cd-8671-5b7b917919f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from logging_utils.logger import get_logger\n",
    "from logging_utils.logging_config import setup_logging\n",
    "# === Project Modules ===\n",
    "\n",
    "from pdf_importer import run_pdf_ingestion_pipeline\n",
    "from utils.vector_search_utils import create_endpoint, delete_index, get_index, create_index, index_exists\n",
    "\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from utils.rag_analytics import *\n",
    "from logging_utils.run_logger import setup_run_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b75f790-5269-49a3-80fc-fd6255256afd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Experiment Directory ===\n",
    "EXPERIMENT_ROOT = \"experiments\"\n",
    "os.makedirs(EXPERIMENT_ROOT, exist_ok=True)\n",
    "\n",
    "setup_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "logger.info(\"Notebook started\")\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"file_path\", StringType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"author\", StringType()),\n",
    "    StructField(\"subject\", StringType()),\n",
    "    StructField(\"keywords\", StringType()),\n",
    "    StructField(\"creation_date\", StringType()),\n",
    "    StructField(\"mod_date\", StringType()),\n",
    "    StructField(\"content\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c2bc44-b186-41c7-881f-9d213fcbdd88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def construct_query(row, columns):\n",
    "    ret_str = \"\"\n",
    "    for i in range(0, len(columns)):\n",
    "        ret_str += f\"{columns[i]} {row[columns[i]]}dm, \"\n",
    "    return re.sub(r'[^\\w\\s]', '', ret_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "391a83a6-514f-4fb1-95f1-8ad7cb6d5096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# === Data Processing Pipeline ===\n",
    "def process_policy_data():\n",
    "    vs_config = config[\"vector_search\"]\n",
    "    doc_config = config[\"document_parsing\"]\n",
    "    catalog, schema = config[\"catalog_name\"], config[\"schema_name\"]\n",
    "    \n",
    "\n",
    "    doc_vol_path = f\"/Volumes/sandbox_catalog/default/{doc_config['document_volume']}/\"\n",
    "    text_table_path = f\"{catalog}.{schema}.{doc_config['text_table']}\"\n",
    "    chunk_table_path = f\"{catalog}.{schema}.{doc_config['chunk_table']}\"\n",
    "    run_pdf_ingestion_pipeline(doc_vol_path, text_table_path, chunk_table_path)\n",
    "\n",
    "    # Setup vector search endpoint or fetch existing endpoint\n",
    "    client = VectorSearchClient(disable_notice=True)\n",
    "    \n",
    "    create_endpoint(client, vs_config[\"endpoint_name\"])\n",
    "\n",
    "    # Deletes the old index. This is only necessary if columns are added or removed.\n",
    "    logger.info(index_exists(client, vs_config[\"endpoint_name\"], vs_config[\"index_name\"]))\n",
    "    if vs_config[\"delete_old_index\"] and index_exists(client, vs_config[\"endpoint_name\"], vs_config[\"index_name\"]):\n",
    "        delete_index(client, vs_config[\"index_name\"])\n",
    "        while index_exists(client, vs_config[\"endpoint_name\"], vs_config[\"index_name\"]):\n",
    "            logger.info(\"Waiting for index deletion...\")\n",
    "            time.sleep(5)\n",
    "    # Creates VS Index or Fetches Existing index\n",
    "    index = create_index( \n",
    "        client,\n",
    "        vs_config[\"endpoint_name\"],\n",
    "        vs_config[\"index_name\"],\n",
    "        \"sandbox_catalog.default.gem_text\",\n",
    "        vs_config[\"primary_key\"],\n",
    "        vs_config[\"source_column\"],\n",
    "        vs_config[\"indexed_columns\"],\n",
    "        vs_config[\"embedding_endpoint\"]\n",
    "    )\n",
    "    return index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b489ff4d-8c81-4298-969f-5b879feb81c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Search and Evaluation ===\n",
    "def test_search_accuracy(index, config):\n",
    "    experiment = config[\"experiment\"]\n",
    "    vs_config = config[\"vector_search\"]\n",
    "\n",
    "    test_df = pd.read_csv(experiment[\"test_data_path\"])\n",
    "    policy = test_df[\"policy\"]\n",
    "    claim_lines = test_df.drop(columns=\"policy\")\n",
    "\n",
    "    results_list = []\n",
    "    total = claim_lines.shape[0]\n",
    "    logger.info(f\"Testing {total} claim lines...\")\n",
    "\n",
    "    last_percent = -1\n",
    "    cols = claim_lines.columns\n",
    "    test_start_time = time.time()\n",
    "    \n",
    "    for i, row in claim_lines.iterrows():\n",
    "        percent = int((i / total) * 100)\n",
    "        if percent != last_percent and percent % 5 == 0:\n",
    "            logger.info(f\"Progress: {percent}%\")\n",
    "            last_percent = percent\n",
    "\n",
    "        query_text = construct_query(row, cols)\n",
    "        start_time = time.time()\n",
    "        response = index.similarity_search(\n",
    "            query_text=query_text,\n",
    "            columns=vs_config[\"indexed_columns\"],\n",
    "            num_results=experiment[\"n_results\"],\n",
    "            query_type=experiment[\"search_type\"],\n",
    "            disable_notice=True\n",
    "        )\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        manifest = response.get(\"manifest\", {}).get(\"columns\", [])\n",
    "        raw_results = response.get(\"result\", {}).get(\"data_array\", [])\n",
    "\n",
    "        results = raw_results[:experiment[\"n_results\"]]\n",
    "        columns = [col.get(\"name\") for col in manifest]\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "        for _, match_row in df.iterrows():\n",
    "            result_entry = {\n",
    "                \"claim\": row[\"claim_id\"],\n",
    "                \"query_time\": elapsed,\n",
    "                **match_row.to_dict()\n",
    "            }\n",
    "            results_list.append(result_entry)\n",
    "    \n",
    "    test_end_time = time.time()\n",
    "\n",
    "    logger.info(\"Total query test runtime: %s seconds\" % (test_end_time - test_start_time))\n",
    "    logger.info(\"Average query test runtime: %s seconds\" % ((test_end_time - test_start_time) / total))\n",
    "    logger.info(\"Completed Query Testing\")\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    logger.info(\"Calculating Query Metrics\")\n",
    "    metrics_df = calculate_metrics_parallel(claim_lines, policy, results_df, experiment[\"n_results\"])\n",
    "\n",
    "    return {\"results\": results_df, \"metrics\": metrics_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc1358a7-fc12-4923-81b7-18041f9518ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# === Main Pipeline Test Runner ===\n",
    "def run_pipeline_test():\n",
    "    # Step 1: Load config\n",
    "    experiment = config[\"experiment\"]\n",
    "    doc_config = config[\"document_parsing\"]\n",
    "    vs_config = config[\"vector_search\"]\n",
    "\n",
    "    # Step 2: Setup experiment output directory\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_name = experiment.get(\"name\", \"unnamed_experiment\")\n",
    "    output_dir = os.path.join(EXPERIMENT_ROOT, f\"{experiment_name}_{timestamp}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Step 3: Setup experiment-specific logging\n",
    "    run_logger = setup_run_logger(run_id=experiment_name, log_dir=output_dir)\n",
    "    run_logger.info(f\"Running experiment: {experiment_name}\")\n",
    "    run_logger.info(f\"Logs saved to {output_dir}\")\n",
    "    # Step 4: Save config\n",
    "    save_config(os.path.join(output_dir, \"config.yaml\"))\n",
    "\n",
    "    # Step 5: Build or load index\n",
    "    if False and experiment[\"create_index\"]:\n",
    "        run_logger.info(\"Creating index\")\n",
    "        start_time = time.time()\n",
    "        # index = process_policy_data()\n",
    "        end_time = time.time()\n",
    "\n",
    "        run_logger.info(\"Total policy ingestion test runtime: %s seconds\" % (end_time - start_time))\n",
    "    else:\n",
    "        run_logger.info(\"Skipping index creation, fetching existing index.\")\n",
    "        client = VectorSearchClient(disable_notice=True)\n",
    "        index = get_index(\n",
    "            client,\n",
    "            vs_config[\"endpoint_name\"],\n",
    "            vs_config[\"index_name\"]\n",
    "        )\n",
    "\n",
    "    # Step 6: Perform search and evaluation\n",
    "    if experiment[\"test_search\"]:\n",
    "        results_obj = test_search_accuracy(index=index, config=config)\n",
    "        \n",
    "        run_logger.info(\"Saving results to experiments directory.\")\n",
    "        results_path = os.path.join(output_dir, \"results.csv\")\n",
    "        metrics_path = os.path.join(output_dir, \"metrics.csv\")\n",
    "        plot_path = os.path.join(output_dir, \"plot\")\n",
    "        \n",
    "        # results_obj[\"results\"].to_csv(results_path, index=False)\n",
    "        # results_obj[\"metrics\"].to_csv(metrics_path, index=False)\n",
    "\n",
    "        save_metrics_plot(results_obj[\"metrics\"], plot_path)\n",
    "        save_timings_plot(results_obj[\"results\"]['query_time'], plot_path)\n",
    "        save_precision_recall_plot(results_obj[\"metrics\"], plot_path)\n",
    "        save_metric_distributions(results_obj[\"metrics\"], plot_path)\n",
    "\n",
    "        run_logger.info(f\"Results saved to {results_path}\")\n",
    "        run_logger.info(f\"Metrics saved to {metrics_path}\")\n",
    "\n",
    "        return results_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87b5f147-be19-474c-a053-3b01cd15592e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_res = run_pipeline_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a268f14-0d21-467f-9a46-6dfdd50aaa31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GEM-PDF-Processing-Test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
